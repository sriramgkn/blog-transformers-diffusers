{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Transformers and Diffusers\n",
        "\n",
        "Cite like this [[0](#ref-0)].\n",
        "Jupyter instructions: install [transformers](https://huggingface.co/docs/transformers/en/installation) and [diffusers](https://huggingface.co/docs/diffusers/en/installation) in your Python environment.\n",
        "\n",
        "In this post, we will explore [Transformers](https://huggingface.co/docs/transformers/index) and [Diffusers](https://huggingface.co/docs/diffusers/en/index) - two popular generative AI libraries by HuggingFace, both based on the transformer architecture in Python.\n",
        "\n",
        "## HuggingFace Transformers Library\n",
        "\n",
        "The HuggingFace Transformers library provides state-of-the-art pre-trained models for natural language processing (NLP), computer vision, and audio tasks. It supports popular transformer architectures like BERT, GPT, RoBERTa, ViT, and more.\n",
        "\n",
        "Key features of the Transformers library include:\n",
        "- Thousands of pre-trained models that can be used for transfer learning or fine-tuning on downstream tasks\n",
        "- Interoperability between PyTorch, TensorFlow, and JAX frameworks\n",
        "- High-level APIs like `pipeline()` for easy inference on common tasks\n",
        "- Low-level APIs for more flexibility and customization\n",
        "- Detailed documentation, tutorials, and an active community\n",
        "\n",
        "### Installation\n",
        "\n",
        "The Transformers library can be easily installed with pip:\n",
        "\n",
        "```bash\n",
        "pip install transformers\n",
        "```\n",
        "\n",
        "### Example: Text Classification\n",
        "\n",
        "Here's an example of using a pre-trained BERT model for text classification with the `pipeline` API:\n"
      ],
      "metadata": {
        "id": "LcZ68UjXQ6om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "result = classifier(\"I absolutely loved this movie! The acting was superb.\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "HGn4q2Xy1eSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "```\n",
        "[{'label': 'POSITIVE', 'score': 0.9998801946640015}]\n",
        "```"
      ],
      "metadata": {
        "id": "UZ7seWV2gYu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: Question Answering\n",
        "\n",
        "Here's an example of using a pre-trained model for question answering:"
      ],
      "metadata": {
        "id": "jbT8z54KgeTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "context = \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\"\n",
        "question = \"Where is the Eiffel Tower located?\"\n",
        "\n",
        "result = qa_model(question=question, context=context)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "iMb2fQCbghKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output:\n",
        "```\n",
        "{'score': 0.9940124392509461, 'start': 35, 'end': 47, 'answer': 'Champ de Mars'}\n",
        "```"
      ],
      "metadata": {
        "id": "A1e5THOugj2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformers library provides a wide range of capabilities for NLP tasks. You can explore more examples and tutorials in the official documentation [[4](#ref-4)].\n",
        "\n",
        "## HuggingFace Diffusers Library\n",
        "\n",
        "The HuggingFace Diffusers library focuses on diffusion models for generative tasks like image generation, audio generation, and even generating 3D structures of molecules. It provides pre-trained diffusion models, interchangeable noise schedulers, and modular components for building custom diffusion systems.\n",
        "\n",
        "Key features of the Diffusers library include:\n",
        "- State-of-the-art diffusion pipelines for inference with just a few lines of code\n",
        "- Flexibility to balance trade-offs between generation speed and quality\n",
        "- Modular design for creating custom end-to-end diffusion systems\n",
        "- Integration with the Hugging Face Hub for sharing and discovering models\n",
        "\n",
        "### Installation\n",
        "\n",
        "The Diffusers library can be easily installed with pip:\n",
        "\n",
        "```bash\n",
        "pip install diffusers\n",
        "```\n",
        "\n",
        "### Example: Text-to-Image Generation\n",
        "\n",
        "Here's an example of using a pre-trained Stable Diffusion model for text-to-image generation:"
      ],
      "metadata": {
        "id": "_P1_BzLrg8XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "image = pipe(prompt).images[0]\n",
        "image.save(\"astronaut_horse.png\")"
      ],
      "metadata": {
        "id": "MsOnaGLIhINt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet loads the Stable Diffusion v1.5 model, moves it to the GPU, and generates an image based on the provided text prompt [[1](#ref-1)] [[3](#ref-3)].\n",
        "\n",
        "### Example: Image-to-Image Translation\n",
        "\n",
        "Here's an example of using a pre-trained model for image-to-image translation:"
      ],
      "metadata": {
        "id": "1ZlBerk6hJY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Load the image\n",
        "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
        "response = requests.get(url)\n",
        "init_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "init_image = init_image.resize((768, 512))\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"A fantasy landscape, trending on artstation\"\n",
        "\n",
        "images = pipe(prompt=prompt, init_image=init_image, strength=0.75, guidance_scale=7.5).images\n",
        "images[0].save(\"fantasy_landscape.png\")"
      ],
      "metadata": {
        "id": "NHp5g-Q2hOvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet loads an input image, resizes it, and then uses the Stable Diffusion model to generate a new image based on the input image and the provided text prompt [[1](#ref-1)] [[3](#ref-3)].\n",
        "\n",
        "The Diffusers library provides a powerful toolset for generative tasks using diffusion models. You can explore more examples and tutorials in the official documentation [[1](#ref-1)] [[11](#ref-11)] [[18](#ref-18)].\n",
        "\n",
        "In summary, the Hugging Face Transformers and Diffusers libraries are invaluable tools for anyone working with state-of-the-art models in NLP, computer vision, and generative AI. They provide pre-trained models, easy-to-use APIs, and extensive documentation to help you get started quickly and build impressive applications [[4](#ref-4)] [[10](#ref-10)] [[12](#ref-12)]."
      ],
      "metadata": {
        "id": "yValTpyihRw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### References  \n",
        "[0] <a id=\"ref-0\"></a> [https://www.example.com](https://www.example.com)  \n",
        "[1] <a id=\"ref-1\"></a> [towardsdatascience.com: Hugging Face Just Released the Diffusers Library](https://towardsdatascience.com/hugging-face-just-released-the-diffusers-library-846f32845e65)  \n",
        "[2] <a id=\"ref-2\"></a> [microsoft.com: What are Hugging Face Transformers? - Azure Databricks](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/train-model/huggingface/)  \n",
        "[3] <a id=\"ref-3\"></a> [learnopencv.com: Introduction to Hugging Face Diffusers](https://learnopencv.com/hugging-face-diffusers/)  \n",
        "[4] <a id=\"ref-4\"></a> [freecodecamp.org: Hugging Face Transformer Library Overview](https://www.freecodecamp.org/news/hugging-face-transformer-library-overview/)  \n",
        "[5] <a id=\"ref-5\"></a> [philschmid.de: Hugging Face Transformers Examples](https://www.philschmid.de/huggingface-transformers-examples)  \n",
        "[6] <a id=\"ref-6\"></a> [datacamp.com: An Introduction to Using Transformers and Hugging Face](https://www.datacamp.com/tutorial/an-introduction-to-using-transformers-and-hugging-face)  \n",
        "[7] <a id=\"ref-7\"></a> [youtube.com: Hugging Face Transformers Tutorial - Getting Started with NLP](https://www.youtube.com/watch?v=rK02eXm3mfI)  \n",
        "[8] <a id=\"ref-8\"></a> [youtube.com: Hugging Face Transformers - Intro to the Library](https://www.youtube.com/watch?v=jan07gloaRg)  \n",
        "[9] <a id=\"ref-9\"></a> [linkedin.com: How to Get Started with the Diffusers Library by Hugging Face: A Guide](https://www.linkedin.com/pulse/how-get-started-diffusers-library-hugging-face-guide-dushyant-kashyap-kkvuc)  \n",
        "[10] <a id=\"ref-10\"></a> [huggingface.co: Transformers Notebooks](https://huggingface.co/docs/transformers/notebooks)  \n",
        "[11] <a id=\"ref-11\"></a> [huggingface.co: Diffusers Documentation](https://huggingface.co/docs/diffusers/v0.21.0/index)  \n",
        "[12] <a id=\"ref-12\"></a> [huggingface.co: Transformers Documentation](https://huggingface.co/docs/transformers/index)  \n",
        "[13] <a id=\"ref-13\"></a> [huggingface.co: Transformers Documentation v4.15.0](https://huggingface.co/docs/transformers/v4.15.0/en/index)  \n",
        "[14] <a id=\"ref-14\"></a> [huggingface.co: Diffusers Training Overview](https://huggingface.co/docs/diffusers/v0.3.0/en/training/overview)  \n",
        "[15] <a id=\"ref-15\"></a> [huggingface.co: Transformers on the Hugging Face Hub](https://huggingface.co/docs/hub/en/transformers)  \n",
        "[16] <a id=\"ref-16\"></a> [github.com: Hugging Face Diffusers Repository](https://github.com/huggingface/diffusers)  \n",
        "[17] <a id=\"ref-17\"></a> [huggingface.co: Diffusers Basic Training](https://huggingface.co/docs/diffusers/en/tutorials/basic_training)  \n",
        "[18] <a id=\"ref-18\"></a> [huggingface.co: Diffusers Documentation](https://huggingface.co/docs/diffusers/en/index)  \n",
        "[19] <a id=\"ref-19\"></a> [huggingface.co: Diffusers on the Hugging Face Hub](https://huggingface.co/docs/hub/en/diffusers)  \n",
        "[20] <a id=\"ref-20\"></a> [huggingface.co: Diffusers Tutorials Overview](https://huggingface.co/docs/diffusers/en/tutorials/tutorial_overview)  \n",
        "\n",
        "_Assisted by claude-3-opus on [perplexity.ai](https://perplexity.ai)_"
      ],
      "metadata": {
        "id": "TULMR03mRFk4"
      }
    }
  ]
}